---
title: "tidy data"
format: gfm
author: "Beth Jump"
date: "2022-03-23"
execute:
  eval: FALSE
---

## Background

Great explanation [here](https://www.statology.org/long-vs-wide-data/#:~:text=A%20dataset%20can%20be%20written,repeat%20in%20the%20first%20column.) about wide vs long data. Tidy data is data where every variable has its own column. More tidy information [here](https://r4ds.had.co.nz/tidy-data.html). Tidy data closely resembles long data.  

Your data will always be easier to work with in a tidy or long format. Instead of doing something to one variable that is split across columns (like you would in a wide format), you can do something in one column alone. You should practice using `pivot_longer` to get your data into a tidy (long) format. 

**A word of caution: when you are joining two datasets, make sure you know whether each dataset is wide or long and that you know how many rows per person are in each dataset. Ex: if you want to match the case interview data (long format, one row per case), with the test dataset (long format, one row per test), you're going to end up with a dataset that has one row per case per test. This is fine, but you'll need to remember to de-duplicate if you want to count unique people.  

## Wide and long data in action 

### Overview 

Let's go through some examples of wide and long/tidy data. The `palmerpenguins::penguins` data set is a tidy data set, meaning we have one column for each variable. 

```{r}
library(tidyverse)

data <- palmerpenguins::penguins
head(data)
```

We want to look at some summary values related to the distribution of species by year. Here's our long version of those frequencies:

```{r}
data_long <- data %>%
  count(year, species)
data_long
```


Here's our wide version of the frequencies:

```{r}
data_wide <- data_long %>% 
  pivot_wider(names_from = species, 
              values_from = n)
data_wide
```
Note: this format is often a format in which we share data because our data consumers aren't used to looking at long data. It's OK to share data in a wide format but it's best practice to work with data in a long format. 

### Summarizing by year

We want to look at how many penguins were identified each year. 

With wide data:

```{r}
data_wide %>%
  rowwise() %>%
  mutate(total_penguins = sum(Adelie, Chinstrap, Gentoo)) %>%
  ungroup()
```

With long data:

```{r}
data_long %>%
  group_by(year) %>%
  summarize(total_penguins = sum(n),
            .groups = "keep") %>%
  ungroup()
```

They both required about the same amount of code, but the code in the long method is more flexible because it doesn't mention any years explicitly - it just uses the variable name `year`. 

### Summarizing by species

What if we wanted to get the number of total species per year? 

With the wide table, we'd need to sum each species manually:

```{r}
data_wide %>%
  mutate(adelie = sum(Adelie),
         chinstrap = sum(Chinstrap),
         gentoo = sum(Gentoo)) %>%
  slice(1) %>%
  select(adelie, chinstrap, gentoo)
```

With the long table, this is very easy. We can just take the code from above and swap `group_by(year)` with `group_by(species)`:

```{r}
data_long %>%
  group_by(species) %>%
  summarize(total_penguins = sum(n),
            .groups = "keep") %>%
  ungroup()
```

## Working with long data 

There are a few helpful functions to know when working with data in a long format:

- `dplyr::lead()`: this pulls the value from the next row into the current one
- `dplyr::lag()`: the inverse of lead, this pulls the value from the previous row into the current one
- `dplyr::arrange()`: this sorts your data so you know where you're leading and lagging from
- `zoo::rollmean()`: this allows you to calculate a rolling average for a variable

### `lead()` and `lag()`



```{r}

```

### `rollmean()`

# using lead and lag ----------------------------------------
## how can we answer: which days was the case count higher than the previous day?
episode_dates <- sample_data %>%
  count(episode_date) 

# episode_dates_lag + episode_dates_lead both get us to the same place!
episode_dates_lag <- episode_dates %>%
  arrange(episode_date) %>%
  mutate(prev_count = lag(n),
         today_higher_lag = case_when(n > prev_count ~ 1, TRUE ~ 0))

episode_dates_lead <- episode_dates %>%
  arrange(desc(episode_date)) %>% 
  mutate(prev_count = lead(n),
         today_higher_lead = case_when(n > prev_count  ~ 1, TRUE ~ 0))

compare <- episode_dates_lag %>%
  full_join(episode_dates_lead, by = "episode_date") %>%
  select(episode_date, today_higher_lag, today_higher_lead)

episode_dates_roll_avg <- episode_dates %>%
  arrange(episode_date) %>%
  mutate(roll_avg_7d = rollmean(n, k = 7, align = "center", na.pad = T))

# using group_by and arrange to get the first or last in a group ----
## identify the first person in each age group to get COVID
first_per_age <- sample_data %>%
  select(record_id, age, age_cat, episode_date) %>%
  group_by(age_cat) %>%
  arrange(episode_date) %>%
  slice(1) %>%
  ungroup() 

## you can also flag them within a group
infection_ct_per_age <- sample_data %>%
  select(record_id, age, age_cat, episode_date) %>%
  group_by(age_cat) %>%
  arrange(episode_date) %>%
  mutate(infect_count = row_number()) %>%
  ungroup()

## if you want to get the first and last per group
first_last_per_age <- sample_data %>%
  select(record_id, age, age_cat, episode_date) %>%
  group_by(age_cat) %>%
  arrange(episode_date) %>%
  mutate(first_or_last = case_when(row_number() == 1 ~ "first",
                                   row_number() == n() ~ "last")) %>%
  filter(first_or_last %in% c("first", "last")) %>%
  ungroup() %>%
  arrange(age_cat, episode_date)
  # now make it tidy!
  
first_last_per_age %>%
  select(-c(record_id, age)) %>%
  pivot_wider(names_from = first_or_last, values_from = episode_date)
  
# using summarize to get the first or last --------------------------
first_last_per_age_sum <- sample_data %>%
  group_by(age_cat) %>%
  summarize(first = min(episode_date),
            last = max(episode_date),
            .groups = "keep") %>%
  ungroup()
  