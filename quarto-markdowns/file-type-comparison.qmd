---
format: gfm
title: "file type comparison"
author: "Beth Jump"
date: "2024-03-22"
execute:
  eval: false
  message: false
  warning: false
  freeze: auto
---

## Overview

When we load files into R and save files from R, we can sometimes choose which format to use. When we can choose, we should try to optimize for reading and writing speed and size.

Here we'll compare the sizes and speeds for seven file types:

- `.csv`: comma separated value file
- `.xlsx`: Microsoft Excel file
- `.RData`: used to store one or more R objects
- `.RDS`: used to store a single R object
- `.parquet`: compressed, columnar file with more encoding than arrow or feather
- `.feather`: compressed, columnar file for short term storage
- `.arrow`: compressed, columnar file for short term storage

```{r}
library(tidyverse)
library(writexl)
library(readxl)
library(arrow)
library(readr)
library(flextable)
library(microbenchmark)
library(smcepi)
library(gridExtra)
```

## Details

To compare reading and writing times and storage sizes, we'll use a simulated data set that has 100,000 rows and 21 variables. The code to create the data and calculate the time to read and write is all in a separate R file [here](https://github.com/San-Mateo-County-Health-Epidemiology/R-User-Group/blob/main/quarto-markdowns/r-scripts/file-type-comparison.R). 

We use the [`microbenchmark`](https://www.rdocumentation.org/packages/microbenchmark/versions/1.5.0/topics/microbenchmark) package to compare the time needed to read and write the different types of files.  

## Results 

These are the summary numbers for 100 trials: 

```{r}
load(file = "data/file-type-comparison.RDS")

file_info
```

While the `.Rdata` and `.RDS` files take up the least storage space, `.feather` and `.parquet` are the quickest to read and write into R and only take up ~ 1.5 times as much space as the `.Rdata` and `.RDS` files. 

```{r, echo = FALSE, output = TRUE}
third <- "#1FA187FF"
second <- "#B4DE2CFF"
fastest <- "#FDE725FF"

file_type_comp %>%
  select(file_type, size_kb, matches("_mean|_median")) %>%
  arrange(size_kb) %>% 
  flextable() %>%
  highlight(j = "size_kb", i = ~ size_kb == min(size_kb), color = fastest) %>%
  highlight(j = "size_kb", i = ~ size_kb == sort(unique(size_kb))[2], color = second) %>%
  highlight(j = "size_kb", i = ~ size_kb == sort(unique(size_kb))[3], color = third) %>%
  highlight(j = "write_mean", i = ~ write_mean == min(write_mean), color = fastest) %>%
  highlight(j = "write_mean", i = ~ write_mean == sort(unique(write_mean))[2], color = second) %>%
  highlight(j = "write_mean", i = ~ write_mean == sort(unique(write_mean))[3], color = third) %>%
  
  highlight(j = "write_median", i = ~ write_median == min(write_median), color = fastest) %>%
  highlight(j = "write_median", i = ~ write_median == sort(unique(write_median))[2], color = second) %>%
  highlight(j = "write_median", i = ~ write_median == sort(unique(write_median))[3], color = third) %>%
 
  highlight(j = "read_mean", i = ~ read_mean == min(read_mean), color = fastest) %>%
  highlight(j = "read_mean", i = ~ read_mean == sort(unique(read_mean))[2], color = second) %>%
  highlight(j = "read_mean", i = ~ read_mean == sort(unique(read_mean))[3], color = third) %>%
 
  highlight(j = "read_median", i = ~ read_median == min(read_median), color = fastest) %>%
  highlight(j = "read_median", i = ~ read_median == sort(unique(read_median))[2], color = second) %>%
  highlight(j = "read_median", i = ~ read_median == sort(unique(read_median))[3], color = third) 
 
```

The gist here is to try and avoid storing data in `.xlsx`, `.csv` and `.arrow` unless you have a reason to. These take up 2.5-3 times as much space as storing the data in a `.Rdata` or `.RDS` file. 

```{r}
file_type_comp %>% 
  mutate(min_size = min(size_kb),
         relative_size = round(size_kb/min_size, 1),
         color = case_when(relative_size == 1 ~ "smallest",
                           relative_size > 1 & relative_size <= 2 ~ "medium",
                           TRUE ~ "large")) %>%
  ggplot() + 
  geom_col(aes(x = relative_size, 
               y = fct_reorder(file_type, relative_size),
               fill = color)) +
  scale_fill_manual(values = c("large" = third,
                               "medium" = second,
                               "smallest" = fastest)) + 
  theme_gg_smc(plot_lines = "vertical") + 
  labs(title = "Relative size of files",
       caption = "The values plotted here are the relative size of the file compared to the smallest file. <br> For example, the .arrow file is 3 times larger than the .RDS and .Rdata files.",
       x = "",
       y = "")
```
When it comes to writing data from R, 
```{r}
write_box <- file_type_comp %>%
  mutate(write_max = case_when(write_max > 6000 ~ 6000,
                               TRUE ~ write_max)) %>%
  ggplot + 
  geom_boxplot(aes(xmin = write_min,
                   xlower = write_lq,
                   xmiddle = write_median,
                   xupper = write_uq,
                   xmax = write_max,
                   y = fct_reorder(file_type, write_median)),
               stat = "identity") + 
  theme_gg_smc(plot_lines = "horizontal") + 
  labs(title = "Writing files",
       x = "Time in nanoseconds",
       y = "")

write_bar <- file_type_comp %>% 
  mutate(min_med_write = min(write_median),
         relative_write = round(write_median/min_med_write, 1),
         color = case_when(relative_write <= 10 ~ "smallest",
                           relative_write <= 50 ~ "medium",
                           TRUE ~ "large")) %>%
  ggplot() + 
  geom_col(aes(x = relative_write, 
               y = fct_reorder(file_type, relative_write),
               fill = color)) +
  scale_fill_manual(values = c("large" = third,
                               "medium" = second,
                               "smallest" = fastest)) + 
  theme_gg_smc(plot_lines = "vertical") + 
  labs(title = "Relative write time of files",
       caption = "The values plotted here are the relative median write time of the file compared to the smallest median write time <br> For example, the .arrow file is 3 times larger than the .RDS and .Rdata files.",
       x = "",
       y = "")

grid.arrange(write_box, write_bar,
             nrow = 1)

```


```{r}
file_type_comp %>%
  ggplot + 
  geom_boxplot(aes(xmin = read_min,
                   xlower = read_lq,
                   xmiddle = read_median,
                   xupper = read_uq,
                   xmax = read_max,
                   y = fct_reorder(file_type, read_median)),
               stat = "identity") + 
  theme_gg_smc(plot_lines = "horizontal") + 
  labs(title = "Reading files",
       x = "Time in nanoseconds",
       y = "")

```

## Recommendations

-   To share outside of the Epi team: **.xlsx**
    -   You can really only share data with other teams in a .csv or .xlsx. If you save the same dataset in an .xlsx and a .csv, the .xlsx will take up less space, will allow you to create multiple tabs and will allow the end user to add their own formatting without changing the file type. Basically, there is no reason to save a .csv instead of a .xlsx.
    -   Recommended package: \[writexl\](\https://docs.ropensci.org/writexl/). Use the `write_xlsx()` function
        -   `write_xlsx(list(tab1 = data1, tab2 = data2,`Hello world`= data3), path)`
        -   if you use the tick marks (the key to the left of the 1), you can include spaces in the tab names
-   To save for use by other Epis: **feather** or **parquet**
    -   Feather files are slightly larger than parquet files but are faster to read and write into R. Honestly, using feather or parquet will get the job done
    -   A huge pro for using these files is that they can be read into Python and Stata in addition to R
    -   Recommended package: [arrow](https://arrow.apache.org/docs/r/). Use the `write_feather` or `write_parquet`
-   To save for use by other Epis when variable types are important: **.RDS** or **.Rda**
    -   In some cases, it's really important to preserve the variable types in a dataset ex: in the COVID UDF CalREDIE export, the first 30,000 lines for some variables were blank. This meant that you had to increase the `guess_max` to \>30,000 to get data in that column. Otherwise the column came in blank!
