---
format: gfm
title: "file type comparison"
author: "Beth Jump"
date: "2024-03-22"
execute:
  echo: false
  message: false
  warning: false
  freeze: auto
---

## Overview

When we load files into R and save files from R, we can sometimes choose which format to use. When we can choose, we should try to optimize for reading and writing speed and size.

Here we'll compare the sizes and speeds for seven file types:

- `.csv`: comma separated value file
- `.xlsx`: Microsoft Excel file
- `.RData`: used to store one or more R objects
- `.RDS`: used to store a single R object
- `.parquet`: compressed, columnar file with more encoding than arrow or feather
- `.feather`: compressed, columnar file for short term storage
- `.arrow`: compressed, columnar file for short term storage

```{r}
library(tidyverse)
library(writexl)
library(readxl)
library(arrow)
library(readr)
library(flextable)
library(microbenchmark)
library(smcepi)
library(gridExtra)
library(here)
```

## Results

To compare reading and writing times and storage sizes, we'll use a simulated data set that has 100,000 rows and 21 variables. The code to create the data and calculate the time to read and write is all in a separate R file [here](https://github.com/San-Mateo-County-Health-Epidemiology/R-User-Group/blob/main/quarto-markdowns/r-scripts/file-type-comparison.R). 

We use the [`microbenchmark`](https://www.rdocumentation.org/packages/microbenchmark/versions/1.5.0/topics/microbenchmark) package to compare the time needed to read and write the different types of files.  

These are the summary data for 100 trials: 

```{r}
load(here("data", "file-type-comparison.RDS"))

third <- "#1FA187FF"
second <- "#B4DE2CFF"
fastest <- "#FDE725FF"

file_type_comp %>%
  select(file_type, size_kb, matches("_mean|_median")) %>%
  arrange(size_kb) %>% 
  flextable() %>%
  highlight(j = "size_kb", i = ~ size_kb == min(size_kb), color = fastest) %>%
  highlight(j = "size_kb", i = ~ size_kb == sort(unique(size_kb))[2], color = second) %>%
  highlight(j = "size_kb", i = ~ size_kb == sort(unique(size_kb))[3], color = third) %>%
  highlight(j = "write_mean", i = ~ write_mean == min(write_mean), color = fastest) %>%
  highlight(j = "write_mean", i = ~ write_mean == sort(unique(write_mean))[2], color = second) %>%
  highlight(j = "write_mean", i = ~ write_mean == sort(unique(write_mean))[3], color = third) %>%
  
  highlight(j = "write_median", i = ~ write_median == min(write_median), color = fastest) %>%
  highlight(j = "write_median", i = ~ write_median == sort(unique(write_median))[2], color = second) %>%
  highlight(j = "write_median", i = ~ write_median == sort(unique(write_median))[3], color = third) %>%
 
  highlight(j = "read_mean", i = ~ read_mean == min(read_mean), color = fastest) %>%
  highlight(j = "read_mean", i = ~ read_mean == sort(unique(read_mean))[2], color = second) %>%
  highlight(j = "read_mean", i = ~ read_mean == sort(unique(read_mean))[3], color = third) %>%
 
  highlight(j = "read_median", i = ~ read_median == min(read_median), color = fastest) %>%
  highlight(j = "read_median", i = ~ read_median == sort(unique(read_median))[2], color = second) %>%
  highlight(j = "read_median", i = ~ read_median == sort(unique(read_median))[3], color = third) 
 
```

The gist here is to try and avoid storing data in `.xlsx`, `.csv` and `.arrow` unless you have a reason to. These take up 2.5-3 times as much space as storing the data in a `.Rdata` or `.RDS` file and take a lot longer to load into R and write from R. 

While the `.Rdata` and `.RDS` files take up the least storage space, `.feather` and `.parquet` are the quickest to read and write into R and only take up ~ 1.5 times as much space as the `.Rdata` and `.RDS` files. 

## Recommendations

- To share outside of the Epi team: **`.xlsx`**   
  - You can really only share data with other teams in a `.csv` or `.xlsx.` If you save the same data set in an `.xlsx` and a `.csv`, the `.xlsx` will take up less space, will allow you to create multiple tabs and will allow the end user to add their own formatting without changing the file type. Basically, there is no reason to save a `.csv` instead of a `.xlsx.`  
  - Recommended package: [`writexl`](\https://docs.ropensci.org/writexl/). Use the `write_xlsx()` function  
     - `write_xlsx(list(tab1 = data1, tab2 = data2,`Hello world`= data3), path)`  
     - if you use the tick marks (the key to the left of the 1), you can include spaces in the tab names
- To save for use by other Epis: **`.feather`** or **`.parquet`**  
   - `.feather` files are slightly larger than `.parquet` files but are slightly faster to read and write into R
   -  A huge pro for using these files is that they can be read into Python and Stata in addition to R
   -  Recommended package: [arrow](https://arrow.apache.org/docs/r/). Use the `write_feather()` or `write_parquet()` functions
- To save for use by other Epis when variable types are important: **`.RDS`** or **`.Rdata`**
  - When it's really important to preserve the variable types in a data set, save the object in a native R format
  - We did this during COVID with the COVID UDF CalREDIE export. Some variables had blanks for the first 30,000 rows and if you read the file in as a `.tsv`, you would need to increase the `guess_max` to 30,000 to get data in that column! When we saved it as a `.RData` file, we didn't need to worry about `guess_max()`

## Details 

### File sizes

```{r}
file_type_comp %>% 
  mutate(min_size = min(size_kb),
         relative_size = round(size_kb/min_size, 1),
         color = case_when(relative_size == 1 ~ "smallest",
                           relative_size > 1 & relative_size <= 2 ~ "medium",
                           TRUE ~ "large")) %>%
  ggplot() + 
  geom_col(aes(x = relative_size, 
               y = fct_reorder(file_type, relative_size),
               fill = color)) +
  scale_fill_manual(values = c("large" = third,
                               "medium" = second,
                               "smallest" = fastest)) + 
  theme_gg_smc(plot_lines = "vertical") + 
  labs(title = "Relative size of files",
       caption = "The values plotted here are the relative size of the file compared to the smallest file. <br> For example, the .arrow file is 3 times larger than the .RDS and .Rdata files.",
       x = "",
       y = "")
```
### Writing data from R 

```{r}
#| echo: false

file_type_comp %>%
  mutate(write_max = case_when(write_max > 6000 ~ 6000,
                               TRUE ~ write_max)) %>%
  ggplot + 
  geom_boxplot(aes(xmin = write_min,
                   xlower = write_lq,
                   xmiddle = write_median,
                   xupper = write_uq,
                   xmax = write_max,
                   y = fct_reorder(file_type, write_median)),
               stat = "identity") + 
  theme_gg_smc(plot_lines = "horizontal") + 
  labs(title = "Distribution for write time of files",
       x = "Time in nanoseconds",
       y = "")

file_type_comp %>% 
  mutate(min_med_write = min(write_median),
         relative_write = round(write_median/min_med_write, 1),
         color = case_when(relative_write <= 10 ~ "smallest",
                           relative_write <= 50 ~ "medium",
                           TRUE ~ "large")) %>%
  ggplot() + 
  geom_col(aes(x = relative_write, 
               y = fct_reorder(file_type, relative_write),
               fill = color)) +
  scale_fill_manual(values = c("large" = third,
                               "medium" = second,
                               "smallest" = fastest)) + 
  theme_gg_smc(plot_lines = "vertical") + 
  labs(title = "Relative write time of files",
       caption = "The values plotted here are the relative median write time of the file compared to the smallest median write time <br> For example, the .xlsx file takes more than 90 times longer to write from R than the .feather file.",
       x = "",
       y = "")

```
### Reading files into R

```{r}
file_type_comp %>%
  ggplot + 
  geom_boxplot(aes(xmin = read_min,
                   xlower = read_lq,
                   xmiddle = read_median,
                   xupper = read_uq,
                   xmax = read_max,
                   y = fct_reorder(file_type, read_median)),
               stat = "identity") + 
  theme_gg_smc(plot_lines = "horizontal") + 
  theme_gg_smc(plot_lines = "horizontal") + 
  labs(title = "Distribution for read time of files",
       x = "Time in nanoseconds",
       y = "")

file_type_comp %>% 
  mutate(min_med_read = min(read_median),
         relative_read = round(read_median/min_med_read, 1),
         color = case_when(relative_read <= 10 ~ "smallest",
                           relative_read <= 50 ~ "medium",
                           TRUE ~ "large")) %>%
  ggplot() + 
  geom_col(aes(x = relative_read, 
               y = fct_reorder(file_type, relative_read),
               fill = color)) +
  scale_fill_manual(values = c("large" = third,
                               "medium" = second,
                               "smallest" = fastest)) + 
  theme_gg_smc(plot_lines = "vertical") + 
  labs(title = "Relative read time of files",
       caption = "The values plotted here are the relative median read time of the file compared to the smallest median read time <br> For example, the .xlsx file takes more than 90 times longer to read into R than the .feather file.",
       x = "",
       y = "")
```


